{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ec2706d7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.despine()\n",
    "sns.set_context('talk', font_scale = 1)\n",
    "import statsmodels.formula.api as smf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Balance</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marriage</th>\n",
       "      <th>Age</th>\n",
       "      <th>Paid_Sep</th>\n",
       "      <th>Paid_Aug</th>\n",
       "      <th>Paid_Jul</th>\n",
       "      <th>Paid_Jun</th>\n",
       "      <th>Paid_May</th>\n",
       "      <th>...</th>\n",
       "      <th>Bill_Jun</th>\n",
       "      <th>Bill_May</th>\n",
       "      <th>Bill_Apr</th>\n",
       "      <th>PayAmt_Sep</th>\n",
       "      <th>PayAmt_Aug</th>\n",
       "      <th>PayAmt_Jul</th>\n",
       "      <th>PayAmt_Jun</th>\n",
       "      <th>PayAmt_May</th>\n",
       "      <th>PayAmt_Apr</th>\n",
       "      <th>Default</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Balance  Sex  Education  Marriage  Age  Paid_Sep  Paid_Aug  Paid_Jul  \\\n",
       "ID                                                                         \n",
       "1     20000    2          2         1   24         2         2        -1   \n",
       "2    120000    2          2         2   26        -1         2         0   \n",
       "3     90000    2          2         2   34         0         0         0   \n",
       "4     50000    2          2         1   37         0         0         0   \n",
       "5     50000    1          2         1   57        -1         0        -1   \n",
       "\n",
       "    Paid_Jun  Paid_May   ...     Bill_Jun  Bill_May  Bill_Apr  PayAmt_Sep  \\\n",
       "ID                       ...                                                \n",
       "1         -1        -2   ...            0         0         0           0   \n",
       "2          0         0   ...         3272      3455      3261           0   \n",
       "3          0         0   ...        14331     14948     15549        1518   \n",
       "4          0         0   ...        28314     28959     29547        2000   \n",
       "5          0         0   ...        20940     19146     19131        2000   \n",
       "\n",
       "    PayAmt_Aug  PayAmt_Jul  PayAmt_Jun  PayAmt_May  PayAmt_Apr  Default  \n",
       "ID                                                                       \n",
       "1          689           0           0           0           0        1  \n",
       "2         1000        1000        1000           0        2000        1  \n",
       "3         1500        1000        1000        1000        5000        0  \n",
       "4         2019        1200        1100        1069        1000        0  \n",
       "5        36681       10000        9000         689         679        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def InitiateData():\n",
    "    '''\n",
    "    Imports the data set and prepare it for EDA and modelling\n",
    "    '''\n",
    "    global data\n",
    "    \n",
    "    data = pd.read_excel('default of credit card clients.xls', header=1, index_col=0)\n",
    "\n",
    "    col_names = ['Balance', 'Sex', 'Education', 'Marriage', 'Age',\n",
    "                'Paid_Sep', 'Paid_Aug', 'Paid_Jul', 'Paid_Jun', 'Paid_May', 'Paid_Apr',\n",
    "                'Bill_Sep', 'Bill_Aug', 'Bill_Jul', 'Bill_Jun', 'Bill_May', 'Bill_Apr',\n",
    "                'PayAmt_Sep', 'PayAmt_Aug', 'PayAmt_Jul', 'PayAmt_Jun', 'PayAmt_May', 'PayAmt_Apr',\n",
    "                'Default']\n",
    "    data.columns = col_names\n",
    "    data = data.astype(str).astype(int)\n",
    "    \n",
    "    return data.head()\n",
    "\n",
    "InitiateData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Label response and predictors\n",
    "response =['Default']\n",
    "predictors = [x for x in list(data.columns) if x not in response]\n",
    "\n",
    "# Step 2: Split data set\n",
    "y = data[response].copy()\n",
    "X = data[predictors].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9, random_state=42)\n",
    "\n",
    "# Step 3: Prepare for scaling\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Step 4: Scale the data\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#Basic Boosting\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "tuning_parameters = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators' : [250, 500, 750, 1000, 1500],\n",
    "    'max_depth' : [2 ,3, 4],\n",
    "    'subsample' : [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Using GridSearchCV would be too slow. Increase the number of iterations to explore more hyperparameter combinations.\n",
    "gb = RandomizedSearchCV(model, tuning_parameters, n_iter = 20, cv = 10, return_train_score=False, n_jobs=4, random_state = 20)\n",
    "\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "gb = gb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=3000, minmax=(0.00312916857941082, 0.9847440468334795), mean=0.22539070559329089, variance=0.03911565682341456, skewness=1.5946358972376458, kurtosis=1.795751873769099)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.describe(gb.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#XGBoost\n",
    "import xgboost as xgb\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "\n",
    "tuning_parameters = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators' : [250, 500, 750, 1000, 1500],\n",
    "    'max_depth' : [2, 3, 4],\n",
    "    'subsample' : [0.6, 0.8, 1.0],\n",
    "}\n",
    "\n",
    "gb_search = RandomizedSearchCV(model, tuning_parameters, n_iter = 16, cv = 5, return_train_score=False, n_jobs=4,\n",
    "                              random_state = 20)\n",
    "gb_search.fit(X_train, y_train)\n",
    "\n",
    "xbst = gb_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=3000, minmax=(0, 1), mean=0.11833333333333333, variance=0.10436534400355676, skewness=2.363243475881673, kurtosis=3.584919726297291)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.describe(xbst.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 56.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import lightgbm as lgb\n",
    "model = lgb.LGBMClassifier()\n",
    "\n",
    "\n",
    "tuning_parameters = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators' : [250, 500, 750, 1000, 1500],\n",
    "    'max_depth' : [2, 3, 4],\n",
    "    'subsample' : [0.6, 0.8, 1.0],\n",
    "}\n",
    "\n",
    "gb_search = RandomizedSearchCV(model, tuning_parameters, n_iter = 16, cv = 5, return_train_score=False, n_jobs=4, \n",
    "                               random_state = 20)\n",
    "\n",
    "gb_search.fit(X_train, y_train)\n",
    "\n",
    "lbst = gb_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "lasso = Pipeline((\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('estimator', LassoCV(cv=5)),\n",
    "))\n",
    "\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "y_fit = lasso.predict(X_train)\n",
    "resid = y_train['Default'].values - y_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=3000, minmax=(0, 1), mean=0.115, variance=0.10180893631210405, skewness=2.413627079052996, kurtosis=3.825595676737901)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.describe(lbst.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          fit_params=None, iid=True, n_iter=4, n_jobs=4,\n",
       "          param_distributions={'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n",
       "          pre_dispatch='2*n_jobs', random_state=20, refit=True,\n",
       "          return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(gamma='auto')\n",
    "tuning_parameters = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(model, tuning_parameters, n_iter = 4, cv = 10, return_train_score=False, n_jobs=4, random_state = 20)\n",
    "\n",
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=3000, minmax=(0, 1), mean=0.10366666666666667, variance=0.09295087251305992, skewness=2.600376632074569, kurtosis=4.7619586286394835)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.describe(clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 1s 324us/step - loss: 0.5661 - acc: 0.7737\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 0s 138us/step - loss: 0.5009 - acc: 0.7747\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 0s 128us/step - loss: 0.4902 - acc: 0.7747\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 0s 127us/step - loss: 0.4830 - acc: 0.7747\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 1s 171us/step - loss: 0.4771 - acc: 0.7773\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 0s 139us/step - loss: 0.4731 - acc: 0.8013\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 1s 182us/step - loss: 0.4705 - acc: 0.8083\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 0s 165us/step - loss: 0.4680 - acc: 0.8117\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 1s 169us/step - loss: 0.4651 - acc: 0.8110\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 0s 120us/step - loss: 0.4635 - acc: 0.8143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ec313693c8>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "NN = Sequential()\n",
    "\n",
    "# Layers\n",
    "NN.add(Dense(output_dim = 10, init = 'uniform', activation = 'relu'))\n",
    "NN.add(Dense(output_dim = 10, init = 'uniform', activation = 'relu'))\n",
    "NN.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling Neural Network\n",
    "NN.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "NN.fit(X_train, y_train['Default'].values, batch_size = 10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.224285  ],\n",
       "       [0.17293058],\n",
       "       [0.21888234],\n",
       "       ...,\n",
       "       [0.63648164],\n",
       "       [0.06232405],\n",
       "       [0.5088713 ]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idk how to put logistic regression as the meta_classifier \n",
    "    # Been trying to find that out but haven't found out that yet\n",
    "    # Could be \"lr\" but idk if that means logistic regression\n",
    "    # I believe it is based on this (https://rasbt.github.io/mlxtend/user_guide/classifier/StackingClassifier/#example-3-stacked-classification-and-gridsearch)\n",
    "        # Look at this example's output \n",
    "\n",
    "#%%time\n",
    "#\n",
    "#from mlxtend.classifier import StackingClassifier\n",
    "#\n",
    "#models = [tree1, tree2, bag, rf]\n",
    "#\n",
    "#stack = StackingClassifier(models, meta_classifier=lr, cv=10)\n",
    "#stack.fit(X_train.values, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, precision_score\n",
    "\n",
    "columns = ['Error rate', 'True Positive Rate', 'True Negative Rate', 'AUC', 'Precision']\n",
    "rows = ['Decision Tree 1', 'Decision Tree 2', 'Bagged Trees', 'Random Forest', 'KNN']\n",
    "results = pd.DataFrame(0.0, columns=columns, index=rows) \n",
    "\n",
    "methods = [tree1, tree2, bag, rf, knn]\n",
    "\n",
    "y_prob = np.zeros((len(test), len(rows)))\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    \n",
    "    y_pred = method.predict(X_test)\n",
    "    y_prob[:, i] = method.predict_proba(X_test)[:,1]\n",
    "\n",
    "    confusion = confusion_matrix(y_test, y_pred) \n",
    "\n",
    "    results.iloc[i,0] = 1 - accuracy_score(y_test, y_pred)\n",
    "    results.iloc[i,1] = confusion[1,1]/np.sum(confusion[1,:])\n",
    "    results.iloc[i,2] = confusion[0,0]/np.sum(confusion[0,:])\n",
    "    results.iloc[i,3] = roc_auc_score(y_test, y_prob[:,i])\n",
    "    results.iloc[i,4] = precision_score(y_test, y_pred)\n",
    "\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves\n",
    "from statlearning import plot_roc_curves\n",
    "\n",
    "with sns.color_palette(crayon):\n",
    "    fig, ax = plot_roc_curves(y_test, y_prob, labels=pd.Series(rows))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
